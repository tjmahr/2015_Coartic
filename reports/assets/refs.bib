@incollection {FernaldLWL,
  author    = {Fernald, Anne and Zangl, Renate and Portillo, Ana Luz and Marchman, Virginia A.},
  title     = {Looking while listening: Using eye movements to monitor spoken language comprehension by infants and young children},
  editor    = {Sekerina, Irina A and Fern{\'a}ndez, Eva M and Clahsen, Harald},
  booktitle = {Developmental Psycholinguistics: On-line methods in children's language processing},
  publisher = {John Benjamins Publishing Company},
  address   = {Amsterdam},
  year      = {2008},
  pages     = {97--135},
  abstract  = {The "looking-while-listening" methodology uses real-time
               measures of the time course of young children's gaze patterns in
               response to speech. This procedure is low in task demands and does not
               require automated eyetracking technology, similar to
               "preferential-looking" procedures. However, the looking-while-listening
               methodology differs critically from preferential-looking procedures in
               the methods used for data reduction and analysis, yielding
               high-resolution measures of speech processing from moment to moment,
               rather than relying on summary measures of looking preference. Because
               children's gaze patterns are time-locked to the speech signal and coded
               frame-by-frame, response latencies can be coded with millisecond
               precision on multiple trials over multiple items, based on data from
               thousands of frames in each experiment. The meticulous procedures
               required in the collection, reduction, and multiple levels of analysis
               of such detailed data are demanding, but well worth the effort,
               revealing a dynamic and nuanced picture of young children's developing
               skill in finding meaning in spoken language.},
}

@article {GowMcMurray2007,
  author  =  {Gow, Jr., David W. and McMurray, Bob},
  title   =  {Word recognition and phonology: The case of {E}nglish coronal place assimilation},
  journal =  {Papers in laboratory phonology},
  volume  =  {9},
  pages   =  {173--200},
  year    =  {2007}
}

@article {Salverda2014,
  author    = {Salverda, Anne Pier and Kleinschmidt, Dave and Tanenhaus, Michael K.},
  title     = {Immediate effects of anticipatory coarticulation in spoken-word recognition},
  doi       = {10.1016/j.jml.2013.11.002},
  journal   = {Journal of memory and language},
  number    = {1},
  pages     = {145--163},
  publisher = {Elsevier},
  url       = {http://www.ncbi.nlm.nih.gov/pubmed/24511179},
  volume    = {71},
  year      = {2014},
  abstract  = {Two visual-world experiments examined listeners' use of pre
               word-onset anticipatory coarticulation in spoken-word recognition.
               Experiment 1 established the shortest lag with which information in the
               speech signal influences eye-movement control, using stimuli such as
               "The \ldots ladder is the target". With a neutral token of the definite
               article preceding the target word, saccades to the referent were not
               more likely than saccades to an unrelated distractor until 200-240 ms
               after the onset of the target word. In Experiment 2, utterances
               contained definite articles which contained natural anticipatory
               coarticulation pertaining to the onset of the target word ("The ladder
               \ldots is the target"). A simple Gaussian classifier was able to predict
               the initial sound of the upcoming target word from formant information
               from the first few pitch periods of the article's vowel. With these
               stimuli, effects of speech on eye-movement control began about 70 ms
               earlier than in Experiment 1, suggesting rapid use of anticipatory
               coarticulation. The results are interpreted as support for "data
               explanation" approaches to spoken-word recognition. Methodological
               implications for visual-world studies are also discussed.},
}

@article {Weisleder2013,
  author   = {Weisleder, Adriana and Fernald, Anne},
  title    = {Talking to children matters: early language experience strengthens processing and builds vocabulary},
  doi      = {10.1177/0956797613488145},
  journal  = {Psychological science},
  number   = {11},
  pages    = {2143--52},
  volume   = {24},
  year     = {2013},
  abstract = {Infants differ substantially in their rates of language
              growth, and slow growth predicts later academic difficulties. In this
              study, we explored how the amount of speech directed to infants in
              Spanish-speaking families low in socioeconomic status influenced the
              development of children's skill in real-time language processing and
              vocabulary learning. All-day recordings of parent-infant interactions at
              home revealed striking variability among families in how much speech
              caregivers addressed to their child. Infants who experienced more
              child-directed speech became more efficient in processing familiar words
              in real time and had larger expressive vocabularies by the age of 24
              months, although speech simply overheard by the child was unrelated to
              vocabulary outcomes. Mediation analyses showed that the effect of
              child-directed speech on expressive vocabulary was explained by infants'
              language-processing efficiency, which suggests that richer language
              experience strengthens processing skills that facilitate language
              growth.},
}

@article {MarchmanFernald2008,
  author   = {Marchman, Virginia A. and Fernald, Anne},
  title    = {Speed of word recognition and vocabulary knowledge in infancy predict cognitive and language outcomes in later childhood},
  doi      = {10.1111/j.1467-7687.2008.00671.x},
  journal  = {Developmental science},
  number   = {3},
  pages    = {F9--16},
  volume   = {11},
  year     = {2008},
  abstract = {The nature of predictive relations between early language
              and later cognitive function is a fundamental question in research on
              human cognition. In a longitudinal study assessing speed of language
              processing in infancy, Fernald, Perfors and Marchman (2006) found that
              reaction time at 25 months was strongly related to lexical and
              grammatical development over the second year. In this follow-up study,
              children originally tested as infants were assessed at 8 years on
              standardized tests of language, cognition, and working memory. Speed of
              spoken word recognition and vocabulary size at 25 months each accounted
              for unique variance in linguistic and cognitive skills at 8 years,
              effects that were attributable to strong relations between both infancy
              measures and working memory. These findings suggest that processing
              speed and early language skills are fundamental to intellectual
              functioning, and that language development is guided by learning and
              representational principles shared across cognitive and linguistic
              domains.},
}

@incollection {LawfulVariability,
  author    = {Elman, Jeffrey L. and McClelland, James L.},
  title     = {Exploiting lawful variability in the speech wave},
  address   = {Hillsdale, NJ},
  booktitle = {Invariance and variability of speech processes},
  editor    = {Perkell, J. S. and Klatt, D. H.},
  pages     = {360--385},
  publisher = {Lawrence Erlbaum Associates, Inc.},
  year      = {1986},
}

@article {SubcatMismatch,
  author  = {Dahan, Delphine and Magnuson, James S. and Tanenhaus, Michael K. and Hogan, Ellen M.},
  title   = {Subcategorical mismatches and the time course of lexical access: Evidence for lexical competition},
  doi     = {10.1080/01690960143000074},
  journal = {Language and Cognitive Processes},
  number  = {5--6},
  pages   = {507--534},
  volume  = {16},
  year    = {2001},
}

@article {McQueen1999,
  title    = {Lexical influence in phonetic decision making: Evidence from subcategorical mismatches},
  author   = {McQueen, James M. and Norris, Dennis and Cutler, Anne},
  doi      = {10.1037/0096-1523.25.5.1363},
  journal  = {Journal of Experimental Psychology: Human Perception and Performance},
  number   = {5},
  pages    = {1363--1389},
  volume   = {25},
  year     = {1999},
  abstract = {In 5 experiments, listeners heard words and nonwords, some
              cross-spliced so that they contained acoustic-phonetic mismatches.
              Performance was worse on mismatching than on matching items. Words
              cross-spliced with words and words cross-spliced with nonwords produced
              parallel results. However, in lexical decision and 1 of 3 phonetic
              decision experiments, performance on nonwords cross-spliced with words
              was poorer than on nonwords cross-spliced with nonwords. A gating study
              confirmed that there were misleading coarticulatory cues in the
              cross-spliced items; a sixth experiment showed that the earlier results
              were not due to interitem differences in the strength of these cues.
              Three models of phonetic decision making (the Race model, the TRACE
              model, and a postlexical model) did not explain the data. A new
              bottom-up model is outlined that accounts for the findings in terms of
              lexical involvement at a dedicated decision-making stage.},
}

@inproceedings {Tobin2010,
  title     = {Effects of anticipatory coarticulation on lexical access},
  author    = {Tobin, Stephen and Cho, Pyeong Whan and Jennet, Patrick and Magnuson, James S.},
  booktitle = {Proceedings of the 32nd Annual Meeting of the Cognitive Science Society},
  editor    = {Ohlsson, Stellan and Catrambone, Richard},
  pages     = {2200--2205},
  address   = {Austin, TX},
  publisher = {Cognitive Science Society},
  year      = {2010},
  abstract  = {One of the most challenging unsolved problems in cognitive
               science is lack of invariance in spoken language. We take the view that
               variability due to coarticulation is systematic and beneficial. Several
               recent eye tracking experiments have demonstrated listeners' sensitivity
               to local coarticulatory cues between adjacent phonemes. We examined
               sensitivity to longer-range, anticipatory vowel-to-vowel coarticulation,
               which can spread across multiple syllables. Using a variant of the
               Visual World eye tracking paradigm (Tanenhaus et al., 1995), we
               conducted the first on-line test of whether lexical access is sensitive
               to such subtle, long-range cues, and whether the impact of such cues is
               modulated by the coarticulation resistance of intervening segments.
               Lexical access was delayed when misleading anticipatory coarticulation
               was available in cross-spliced materials. This significantly extends the
               nature and temporal range of subcategorical cues known to influence
               on-line sentence comprehension, and demonstrates that lexical access is
               simultaneously constrained by information at multiple temporal grains.},
}

@incollection {Fisher2004,
  title     = {Learning to identify spoken words},
  author    = {Fisher, Cynthia and Church, Barbara A. and Chambers, Kyle E},
  booktitle = {Weaving a lexicon},
  editor    = {Hall, D. Geoffrey and Waxman, Sandra R.},
  pages     = {3--40},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  year      = {2004},
}

@article {JohnsonJusczyk2001,
  title    = {Word Segmentation by 8-Month-Olds: When Speech Cues Count More Than Statistics},
  author   = {Johnson, Elizabeth K. and Jusczyk, Peter W.},
  doi      = {10.1006/jmla.2000.2755},
  journal  = {Journal of Memory and Language},
  number   = {4},
  pages    = {548--567},
  volume   = {44},
  year     = {2001},
  abstract = {Fluent speech contains few pauses between adjacent words.
              Cues such as stress, phonotactic constraints, and the statistical
              structure of the input aid infants in discovering word boundaries. None
              of the many available segmentation cues is foolproof. So, we used the
              headturn preference procedure to investigate infants' integration of
              multiple cues. We also explored whether infants find speech cues
              produced by coarticulation useful in word segmentation. Using natural
              speech syllables, we replicated Saffran, Aslin, et al.'s (1996) study
              demonstrating that 8-month-olds can segment a continuous stream of
              speech based on statistical cues alone. Next, we added conflicting
              segmentation cues. Experiment 2 pitted stress against statistics,
              whereas Experiment 3 pitted coarticulation against statistics. In both
              cases, 8-month-olds weighed speech cues more heavily than statistical
              cues. This observation was verified in Experiment 4, which indicated
              that greater complexity of the familiarization sequence does not
              necessarily lead to familiarity effects.},
}

@article {Swingley1999,
  title    = {Continuous processing in word recognition at 24 months},
  author   = {Swingley, Daniel and Pinto, John P and Fernald, Anne},
  doi      = {10.1016/S0010-0277(99)00021-9},
  journal  = {Cognition},
  number   = {2},
  pages    = {73--108},
  volume   = {71},
  year     = {1999},
  abstract = {Speech processing in adults in continuous: as
              acoustic-phonetic information is heard, listeners' interpretation of the
              speech is updated incrementally. The present studies used a visual
              fixation technique to examine whether young children also interpret
              speech continuously. In Experiments 1 and 2, 24-month-old children
              looked at visual displays while hearing sentences. Sentences each
              contained a target word labeling one of the two displayed pictures.
              Children's latency to fixate the labeled picture was measured.
              Children's responses were delayed when the competing distractor
              picture's label overlapped phonetically with the target at onset
              (dog-doll), but not when the pictures' labels rhymed (ball-doll),
              showing that children monitored the speech stream incrementally for
              acoustic-phonetic information specifying the correct picture. In
              Experiment 3, adults' responses in the same task were found to be very
              similar to those of the 24-month-olds. This research shows that by 24
              months, children can interpret speech continuously.},
}

@article {Fernald2001,
  title    = {When half a word is enough: infants can recognize spoken words using partial phonetic information},
  author   = {Fernald, Anne and Swingley, Daniel and Pinto, John P.},
  doi      = {10.1111/1467-8624.00331},
  journal  = {Child development},
  number   = {4},
  pages    = {1003--15},
  volume   = {72},
  year     = {2001},
  abstract = {Adults process speech incrementally, rapidly identifying
              spoken words on the basis of initial phonetic information sufficient to
              distinguish them from alternatives. In this study, infants in the second
              year also made use of word-initial information to understand fluent
              speech. The time course of comprehension was examined by tracking
              infants' eye movements as they looked at pictures in response to
              familiar spoken words, presented both as whole words in intact form and
              as partial words in which only the first 300 ms of the word was heard.
              In Experiment 1, 21-month-old infants (N = 32) recognized partial words
              as quickly and reliably as they recognized whole words; in Experiment 2,
              these findings were replicated with 18-month-old infants (N = 32).
              Combining the data from both experiments, efficiency in spoken word
              recognition was examined in relation to level of lexical development.
              Infants with more than 100 words in their productive vocabulary were
              more accurate in identifying familiar words than were infants with less
              than 60 words. Grouped by response speed, infants with faster mean
              reaction times were more accurate in word recognition and also had
              larger productive vocabularies than infants with slower response
              latencies. These results show that infants in the second year are
              capable of incremental speech processing even before entering the
              vocabulary spurt, and that lexical growth is associated with increased
              speed and efficiency in understanding spoken language.},
}

@article {Barr2008,
  title    = {Analyzing ‘visual world’ eyetracking data using multilevel logistic regression},
  author   = {Barr, Dale J.},
  doi      = {10.1016/j.jml.2007.09.002},
  journal  = {Journal of Memory and Language},
  number   = {4},
  pages    = {457--474},
  volume   = {59},
  year     = {2008},
  abstract = {A new framework is offered that uses multilevel logistic
              regression (MLR) to analyze data from ‘visual world’ eyetracking
              experiments used in psycholinguistic research. The MLR framework
              overcomes some of the problems with conventional analyses, making it
              possible to incorporate time as a continuous variable and gaze location
              as a categorical dependent variable. The multilevel approach minimizes
              the need for data aggregation and thus provides a more statistically
              powerful approach. With MLR, the researcher builds a mathematical model
              of the overall response curve that separates the response into different
              temporal components. The researcher can test hypotheses by examining the
              impact of independent variables and their interactions on these
              components. A worked example using MLR is provided.},
}

@book {Mirman2014,
  title     = {Growth Curve Analysis and Visualization Using {R}},
  author    = {Mirman, Daniel},
  address   = {Boca Raton, FL},
  publisher = {Chapman \& Hall/CRC},
  year      = {2014},
}

@manual {lme4,
  title  = {{lme4}: Linear mixed-effects models using {Eigen} and {S4}},
  author = {Douglas Bates and Martin M\"{a}chler and Ben Bolker and Steven Walker},
  year   = {2014},
  note   = {R package version 1.1-7},
  url    = {http://CRAN.R-project.org/package=lme4},
}


@article {Bates2014,
    archivePrefix = {arXiv},
    arxivId = {1406.5823},
    author = {Douglas Bates and Martin M\"{a}chler and Ben Bolker and Steven Walker},
    eprint = {1406.5823},
    title = {Fitting Linear Mixed-Effects Models using {lme4}},
    url = {http://arxiv.org/abs/1406.5823},
    year = {2014},
}


@book {MBCDI,
  title     = {{MacArthur-Bates Communicative Development Inventories: User's} Guide and Technical Manual},
  author    = {Larry Fenson and Virginia A. Marchman and Donna J. Thal and Philip S. Dale and J. Steven Reznick and Elizabeth Bates},
  edition   = {2nd ed.},
  year      = {2007},
  publisher = {Brookes},
  address   = {Baltimore, MD},
}

@article {CharlesLuce1990,
  title    = {Similarity neighbourhoods of words in young children's lexicons},
  author   = {Charles-Luce, Jan and Luce, Paul A},
  journal  = {Journal of Child Language},
  volume   = {17},
  number   = {1},
  doi      = {10.1017/S0305000900013180},
  pages    = {205--215},
  year     = {1990},
  abstract = {Similarity neighbourhoods for words in young children's
              lexicons were investigated using three computerized databases. These
              databases were representative of three groups of native English
              speakers: 5-year-olds, 7-year-olds, and adults. Computations relating to
              the similarity neighbourhoods of words in the children's and adult's
              lexicon revealed that words in the 5- and 7-year-olds' lexicons have
              many fewer similar neighbours than the same words analyzed in the adult
              lexicon. Thus, young children may employ more global recognition
              strategies because words are more discriminable in memory. The
              neighbourhood analyses provide a number of insights into the processes
              of auditory word recognition in children and the possible structural
              organization of words in the young child's mental lexicon.},
}

@article {CharlesLuce1995,
  author   = {Charles-Luce, Jan and Luce, Paul A.},
  title    = {An examination of similarity neighbourhoods in young children's receptive vocabularies},
  journal  = {Journal of Child Language},
  volume   = {22},
  number   = {3},
  year     = {1995},
  pages    = {727--735},
  doi      = {10.1017/S0305000900010023},
  abstract = {Based on an analysis of similarity neighbourhoods of words
              in children's lexicons, Dollaghan (1994) argues that because of the
              degree of phonological overlap among lexical items in memory, children
              must perform detailed acoustic-phonetic analyses in order to recognize
              spoken words. This is in contradiction to Charles-Luce \& Luce (1990),
              who reported that the similarity neighbourhoods in younger children's
              expressive lexicons are sparse relative to older children's and adult
              lexicons and that young children may be able to use more global word
              recognition strategies. The current investigation re-examined these
              issues. Similarity neighbourhoods of young children's RECEPTIVE
              vocabularies were analysed for three-phoneme, four-phoneme and
              five-phoneme words. The pattern of the original results from
              Charles-Luce \& Luce (1990) was replicated.},
}

@article {Jusczyk1993WRAPSA,
  title   = {From general to language-specific capacities: The {WRAPSA} model of how speech perception develops},
  author  = {Jusczyk, Peter W.},
  journal = {Journal of Phonetics},
  volume  = {21},
  pages   = {3--28},
  year    = {1993},
}



@article {Edwards2004,
  author   = {Edwards, Jan and Beckman, Mary E. and Munson, Benjamin},
  title    = {The interaction between vocabulary size and phonotactic probability effects on children's production accuracy and fluency in nonword repetition},
  journal  = {Journal of Speech, Language, and Hearing Research},
  year     = {2004},
  doi      = {10.1044/1092-4388(2004/034)},
  number   = {2},
  pages    = {421--36},
  volume   = {47},
  abstract = {Adults' performance on a variety of tasks suggests that
              phonological processing of nonwords is grounded in generalizations about
              sublexical patterns over all known words. A small body of research
              suggests that children's phonological acquisition is similarly based on
              generalizations over the lexicon. To test this account, production
              accuracy and fluency were examined in nonword repetitions by 104
              children and 22 adults. Stimuli were 22 pairs of nonwords, in which one
              nonword contained a low-frequency or unattested two-phoneme sequence and
              the other contained a high-frequency sequence. For a subset of these
              nonword pairs, segment durations were measured. The same sound was
              produced with a longer duration (less fluently) when it appeared in a
              low-frequency sequence, as compared to a high-frequency sequence.
              Low-frequency sequences were also repeated with lower accuracy than
              high-frequency sequences. Moreover, children with smaller vocabularies
              showed a larger influence of frequency on accuracy than children with
              larger vocabularies. Taken together, these results provide support for a
              model of phonological acquisition in which knowledge of sublexical units
              emerges from generalizations made over lexical items.},
}

@article {Metsala1999,
  author  = {Metsala, Jamie L.},
  title   = {Young children's phonological awareness and nonword repetition as a function of vocabulary development},
  doi     = {10.1037//0022-0663.91.1.3},
  journal = {Journal of Educational Psychology},
  number  = {1},
  pages   = {3--19},
  volume  = {91},
  year    = {1999},
}

@article {PRIMIR,
  author   = {Werker, Janet F. and Curtin, Suzanne},
  title    = {{PRIMIR: A} Developmental Framework of Infant Speech Processing},
  year     = {2005},
  doi      = {10.1080/15475441.2005.9684216},
  journal  = {Language Learning and Development},
  number   = {2},
  pages    = {197--234},
  volume   = {1},
 abstract  = {Over the past few years, there has been an increasing
              emphasis on studying the link between infant speech perception and later
              language acquisition. This research has yielded some seemingly
              contradictory findings: In some studies infants appear to use phonetic
              and indexical detail that they fail to use in other studies. In this
              article we present a new, unified framework for accounting for these
              divergent findings. PRIMIR (a developmental framework for Processing
              Rich Information from Multidimensional Interactive Representations)
              assumes there is rich information available in the speech input and that
              the child picks up and organizes this information along a number of
              multidimensional interactive planes. Use of this rich information
              depends on the joint activity of 3 dynamic filters. These filters-the
              initial biases, the developmental level of the child, and requirements
              of the specific language task the child is facing-work together to
              differentially direct attention to 1 (or more) plane. In this article we
              outline the contradictory data that need to be explained, elucidate
              PRIMIR, including its underlying assumptions and overall architecture,
              and compare it to existing frameworks. We conclude by presenting core
              predictions of PRIMIR.},
}

@article {Werker2002,
  author   = {Werker, Janet F. and Fennell, Christopher T. and Corcoran, Kathleen M. and Stager, Christine L.},
  title    = {Infants' Ability to Learn Phonetically Similar Words: Effects of Age and Vocabulary Size},
  year     = {2002},
  doi      = {10.1207/15250000252828226},
  journal  = {Infancy},
  number   = {1},
  pages    = {1--30},
  volume   = {3},
  abstract = {What do novice word learners know about the sound of words?
              Word-learning tasks suggest that young infants (14 months old) confuse
              similar-sounding words, whereas mispronunciation detection tasks suggest
              that slightly older infants (18–24 months old) correctly distinguish
              similar words. Here we explore whether the difficulty at 14 months stems
              from infants' novice status as word learners or whether it is inherent
              in the task demands of learning new words. Results from 3 experiments
              support a developmental explanation. In Experiment 1, infants of 20
              months learned to pair 2 phonetically similar words to 2 different
              objects under precisely the same conditions that infants of 14 months
              (Experiment 2) failed. In Experiment 3, infants of 17 months showed
              intermediate, but still successful, performance in the task. Vocabulary
              size predicted word-learning performance, but only in the younger, less
              experienced word learners. The implications of these results for
              theories of word learning and lexical representation are discussed.},
}

@article {Dollaghan1994,
  title    = {Children's phonological neighbourhoods: half empty or half full?},
  author   = {Dollaghan, Christine A.},
  journal  = {Journal of Child Language},
  volume   = {21},
  number   = {2},
  pages    = {257--271},
  year     = {1994},
  doi      = {10.1017/S0305000900009260},
  abstract = {Charles-Luce & Luce (1990) found smaller phonological similarity
              neighbourhoods in five- and seven-year-old children's expressive
              lexicons than in an adult receptive lexicon, a finding they interpreted
              as evidence that children need not employ fine-grained auditory
              perceptual analyses in lexical processing. In the present investigation,
              neighbourhood sizes were calculated for an expressive lexicon derived
              from two vocabulary lists representative of children aged 1;0 to 3;0
              (Rescorla, 1989; Reznick & Goldsmith, 1989). Over 80% of the words in
              these early lexicons had at least one phonological neighbour; nearly 20%
              had six or more phonological neighbours. Very young children must have
              access to reasonably detailed phonological information in order to
              create and distinguish among such phonologically similar lexical
              entries.},
}

@article {Magnuson2003,
  author   = {Magnuson, James S. and Tanenhaus, Michael K. and Aslin, Richard N. and Dahan, Delphine},
  title    = {The time course of spoken word learning and recognition: studies with artificial lexicons},
  journal  = {Journal of Experimental Psychology: General},
  volume   = {132},
  number   = {2},
  pages    = {202--227},
  year     = {2003},
  doi      = {10.1037/0096-3445.132.2.202},
  abstract = {The time course of spoken word recognition depends largely on the
              frequencies of a word and its competitors, or neighbors
              (similar-sounding words). However, variability in natural lexicons makes
              systematic analysis of frequency and neighbor similarity difficult.
              Artificial lexicons were used to achieve precise control over word
              frequency and phonological similarity. Eye tracking provided time course
              measures of lexical activation and competition (during spoken
              instructions to perform visually guided tasks) both during and after
              word learning, as a function of word frequency, neighbor type, and
              neighbor frequency. Apparent shifts from holistic to incremental
              competitor effects were observed in adults and neural network
              simulations, suggesting such shifts reflect general properties of
              learning rather than changes in the nature of lexical representations.},
}

@article {Swingley2002,
  author   = {Swingley, Daniel and Aslin, Richard N.},
  title    = {Lexical Neighborhoods and the Word-Form Representations of 14-Month-Olds},
  doi      = {10.1111/1467-9280.00485},
  year     = {2002},
  journal  = {Psychological Science},
  number   = {5},
  pages    = {480--484},
  volume   = {13},
  abstract = {The degree to which infants represent phonetic detail in
              words has been a source of controversy in phonology and developmental
              psychology. One prominent hypothesis holds that infants store words in a
              vague or inaccurate form until the learning of similar-sounding
              neighbors forces attention to subtle phonetic distinctions. In the
              experiment reported here, we used a visual fixation task to assess word
              recognition. We present the first evidence indicating that, in fact, the
              lexical representations of 14- and 15-month-olds are encoded in fine
              detail, even when this detail is not functionally necessary for
              distinguishing similar words in the infant's vocabulary. Exposure to
              words is sufficient for well-specified lexical representations, even
              well before the vocabulary spurt. These results suggest developmental
              continuity in infants' representations of speech: As infants begin to
              build a vocabulary and learn word meanings, they use the perceptual
              abilities previously demonstrated in tasks testing the discrimination
              and categorization of meaningless syllables.},
}

@article {Swingley2000,
  author   = {Swingley, Daniel and Aslin, Richard N.},
  title    = {Spoken word recognition and lexical representation in very young children},
  doi      = {10.1016/S0010-0277(00)00081-0},
  journal  = {Cognition},
  number   = {2},
  pages    = {147--66},
  url      = {http://www.ncbi.nlm.nih.gov/pubmed/10856741},
  volume   = {76},
  year     = {2000},
  abstract = {Although children's knowledge of the sound patterns of
              words has been a focus of debate for many years, little is known about
              the lexical representations very young children use in word recognition.
              In particular, researchers have questioned the degree of specificity
              encoded in early lexical representations. The current study addressed
              this issue by presenting 18-23-month-olds with object labels that were
              either correctly pronounced, or mispronounced. Mispronunciations
              involved replacement of one segment with a similar segment, as in
              'baby-vaby'. Children heard sentences containing these words while
              viewing two pictures, one of which was the referent of the sentence.
              Analyses of children's eye movements showed that children recognized the
              spoken words in both conditions, but that recognition was significantly
              poorer when words were mispronounced. The effects of mispronunciation on
              recognition were unrelated to age or to spoken vocabulary size. The
              results suggest that children's representations of familiar words are
              phonetically well-specified, and that this specification may not be a
              consequence of the need to differentiate similar words in production.},
}

@article {WhiteMorgan2008,
  author   = {White, Katherine S. and Morgan, James L.},
  title    = {Sub-segmental detail in early lexical representations},
  year     = {2008},
  doi      = {10.1016/j.jml.2008.03.001},
  journal  = {Journal of Memory and Language},
  number   = {1},
  pages    = {114--132},
  volume   = {59},
}

@article {TRACE_Mispro,
  author   = {Mayor, Julien and Plunkett, Kim},
  title    = {Infant word recognition: Insights from {TRACE} simulations},
  year     = {2014},
  doi      = {10.1016/j.jml.2013.09.009},
  journal  = {Journal of Memory and Language},
  number   = {1},
  pages    = {89--123},
  volume   = {71},
  abstract = {The TRACE model of speech perception (McClelland \& Elman,
              1986) is used to simulate results from the infant word recognition
              literature, to provide a unified, theoretical framework for interpreting
              these findings. In a first set of simulations, we demonstrate how TRACE
              can reconcile apparently conflicting findings suggesting, on the one
              hand, that consonants play a pre-eminent role in lexical acquisition
              (Nespor, Pe\~{n}a \& Mehler, 2003; Nazzi, 2005), and on the other, that
              there is a symmetry in infant sensitivity to vowel and consonant
              mispronunciations of familiar words (Mani \& Plunkett, 2007). In a
              second series of simulations, we use TRACE to simulate infants' graded
              sensitivity to mispronunciations of familiar words as reported by White
              and Morgan (2008). An unexpected outcome is that TRACE fails to
              demonstrate graded sensitivity for White and Morgan's stimuli unless the
              inhibitory parameters in TRACE are substantially reduced. We explore the
              ramifications of this finding for theories of lexical development.
              Finally, TRACE mimics the impact of phonological neighbourhoods on early
              word learning reported by Swingley and Aslin (2007). TRACE offers an
              alternative explanation of these findings in terms of mispronunciations
              of lexical items rather than imputing word learning to infants. Together
              these simulations provide an evaluation of Developmental (Jusczyk, 1993)
              and Familiarity (Metsala, 1999) accounts of word recognition by infants
              and young children. The findings point to a role for both theoretical
              approaches whereby vocabulary structure and content constrain infant
              word recognition in an experience-dependent fashion, and highlight the
              continuity in the processes and representations involved in lexical
              development during the second year of life.},
}


@article {Gow2002,
  author  = {Gow, Jr., David W.},
  title   = {Does {E}nglish coronal place assimilation create lexical ambiguity?},
  year    = {2002},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  doi     = {10.1037/0096-1523.28.1.163},
  number  = {1},
  pages   = {163--179},
  volume  = {28},
}

@article {Mattys2005,
  author   = {Mattys, Sven L. and White, Laurence and Melhorn, James F.},
  title    = {Integration of multiple speech segmentation cues: a hierarchical framework},
  year     = {2005},
  doi      = {10.1037/0096-3445.134.4.477},
  journal  = {Journal of Experimental Psychology: General},
  number   = {4},
  pages    = {477--500},
  volume   = {134},
  abstract = {A central question in psycholinguistic research is how
              listeners isolate words from connected speech despite the paucity of
              clear word-boundary cues in the signal. A large body of empirical
              evidence indicates that word segmentation is promoted by both lexical
              (knowledge-derived) and sublexical (signal-derived) cues. However, an
              account of how these cues operate in combination or in conflict is
              lacking. The present study fills this gap by assessing speech
              segmentation when cues are systematically pitted against each other. The
              results demonstrate that listeners do not assign the same power to all
              segmentation cues; rather, cues are hierarchically integrated, with
              descending weights allocated to lexical, segmental, and prosodic cues.
              Lower level cues drive segmentation when the interpretive conditions are
              altered by a lack of contextual and lexical information or by white
              noise. Taken together, the results call for an integrated, hierarchical,
              and signal-contingent approach to speech segmentation.},
}


@incollection {Plunkett2006,
  author    = {Plunkett, Kim},
  title     = {Learning how to be flexible with words},
  year      = {2006},
  address   = {Cambridge, MA},
  booktitle = {Processes of change in brain and cognitive development: Attention and performance},
  editor    = {Munakata, Y. and Johnson, M.},
  pages     = {233--248},
  publisher = {MIT Press},
  volume    = {XXI},
}
